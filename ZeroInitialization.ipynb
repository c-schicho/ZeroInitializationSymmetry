{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training neural network with zero weight initialization\n",
    "\n",
    "For a detailed explanation of the experiments in this file read the corresponding paper in the repository.\n",
    "\n",
    "In order to see the result of the experiments run the following command from the command line in the project root directory `tensorboard --logdir results`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import Generator\n",
    "from torch.nn import Sigmoid\n",
    "from torch.optim import SGD\n",
    "\n",
    "from data import get_dataloader, seed_worker\n",
    "from models import MNISTFNNModel, MNISTCNNModel, CIFARCNNModel, LogisticRegression, CIFARFNNModel, ResNet50\n",
    "from train import Trainer, TrainerConfig, run_experiment\n",
    "from utils import read_summary_files_to_df, read_gradient_summary_to_df, plot_summary, \\\n",
    "    plot_gradient_distribution_comparison\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 MNIST dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "R_SEED = 4240\n",
    "MNIST_EPOCHS = 5\n",
    "\n",
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Baseline Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.manual_seed(R_SEED)\n",
    "\n",
    "test_loader = get_dataloader(dataset=\"mnist\", train=False, batch_size=100, flatten=True)\n",
    "train_loader, validation_loader = get_dataloader(dataset=\"mnist\", train=True, batch_size=100, flatten=True,\n",
    "                                                 num_workers=1, worker_init_fn=seed_worker, generator=generator)\n",
    "\n",
    "model = LogisticRegression(28 * 28, 10)\n",
    "\n",
    "trainer = Trainer(model, model_name=\"MNIST_LOGISTIC\")\n",
    "trainer.train(train_loader, validation_loader, MNIST_EPOCHS)\n",
    "trainer.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 FNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.1 Models without zero initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.manual_seed(R_SEED)\n",
    "\n",
    "test_loader = get_dataloader(dataset=\"mnist\", train=False, batch_size=100, flatten=True)\n",
    "train_loader, validation_loader = get_dataloader(dataset=\"mnist\", train=True, batch_size=100, flatten=True,\n",
    "                                                 num_workers=1,\n",
    "                                                 worker_init_fn=seed_worker, generator=generator)\n",
    "\n",
    "model = MNISTFNNModel()\n",
    "\n",
    "trainer = Trainer(model, model_name=\"MNIST_FNN\")\n",
    "trainer.train(train_loader, validation_loader, MNIST_EPOCHS)\n",
    "trainer.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.manual_seed(R_SEED)\n",
    "\n",
    "test_loader = get_dataloader(dataset=\"mnist\", train=False, batch_size=16, flatten=True)\n",
    "train_loader, validation_loader = get_dataloader(dataset=\"mnist\", train=True, batch_size=16, flatten=True,\n",
    "                                                 num_workers=1,\n",
    "                                                 worker_init_fn=seed_worker, generator=generator)\n",
    "\n",
    "model = MNISTFNNModel()\n",
    "\n",
    "trainer = Trainer(model, model_name=\"MNIST_FNN_MINI_BATCH\")\n",
    "trainer.train(train_loader, validation_loader, MNIST_EPOCHS)\n",
    "trainer.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.2 Experiments with zero initialisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "configs = [\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_ZERO\", epochs=MNIST_EPOCHS, batch_size=100, initialization_mode=\"zero\"),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_ZERO_SIGMOID\", epochs=MNIST_EPOCHS, batch_size=100, initialization_mode=\"zero\",\n",
    "                  activation_fun=Sigmoid()),\n",
    "\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_NORMAL\", epochs=MNIST_EPOCHS, batch_size=100, initialization_mode=\"normal\"),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_NORMAL_DOWN_SCALED\", epochs=MNIST_EPOCHS, batch_size=100,\n",
    "                  initialization_mode=\"normal\", initialization_factor=.01),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_NORMAL_UP_SCALED\", epochs=MNIST_EPOCHS, batch_size=100,\n",
    "                  initialization_mode=\"normal\", initialization_factor=100),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_NORMAL_SGD\", epochs=MNIST_EPOCHS, batch_size=100, initialization_mode=\"normal\",\n",
    "                  optimizer=SGD),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_NORMAL_MINI_BATCH\", epochs=MNIST_EPOCHS, batch_size=16,\n",
    "                  initialization_mode=\"normal\"),\n",
    "\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_UNIFORM\", epochs=MNIST_EPOCHS, batch_size=100, initialization_mode=\"uniform\"),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_UNIFORM_DOWN_SCALED\", epochs=MNIST_EPOCHS, batch_size=100,\n",
    "                  initialization_mode=\"uniform\", initialization_factor=.01),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_UNIFORM_UP_SCALED\", epochs=MNIST_EPOCHS, batch_size=100,\n",
    "                  initialization_mode=\"uniform\", initialization_factor=100),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_UNIFORM_SGD\", epochs=MNIST_EPOCHS, batch_size=100,\n",
    "                  initialization_mode=\"uniform\",\n",
    "                  optimizer=SGD),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_UNIFORM_MINI_BATCH\", epochs=MNIST_EPOCHS, batch_size=16,\n",
    "                  initialization_mode=\"uniform\"),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for config in configs:\n",
    "    model = MNISTFNNModel(activation_fun=config.activation_fun)\n",
    "    config.optimizer = config.optimizer if config.optimizer is None else config.optimizer(model.parameters(), lr=0.001)\n",
    "    run_experiment(model=model, dataset=\"mnist\", config=config, seed=R_SEED)\n",
    "    del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.3 Final Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.initial_seed()\n",
    "random.seed()\n",
    "np.random.seed()\n",
    "\n",
    "MNIST_EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "RUNS = 5\n",
    "\n",
    "configs = [\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_BASELINE\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                  initialization_mode=\"default\"),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE, initialization_mode=\"default\"),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_NORMAL\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                  initialization_mode=\"normal\"),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_UNIFORM\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                  initialization_mode=\"uniform\"),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_NORMAL_UP_SCALED\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                  initialization_mode=\"normal\", initialization_factor=100),\n",
    "    TrainerConfig(model_name=\"MNIST_FNN_NORMAL_DOWN_SCALED\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                  initialization_mode=\"normal\", initialization_factor=.01),\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    if \"BASELINE\" in config.model_name:\n",
    "        model = LogisticRegression(28 * 28, 10)\n",
    "    else:\n",
    "        model = MNISTFNNModel(activation_fun=config.activation_fun)\n",
    "\n",
    "    run_experiment(model=model, dataset=\"mnist\", config=config, runs=RUNS, train_summary=False,\n",
    "                   validation_summary=False, validate_after_epoch=False, test_after_epoch=True)\n",
    "    del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_baseline_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_FNN_BASELINE\"),\n",
    "                                             model_name=\"Baseline model\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "mnist_fnn_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_FNN\"),\n",
    "                                        model_name=\"LeCun initialization\",\n",
    "                                        n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "mnist_fnn_normal_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_FNN_NORMAL\"),\n",
    "                                               model_name=\"Normal initialization\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "mnist_fnn_uniform_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_FNN_UNIFORM\"),\n",
    "                                                model_name=\"Uniform initialization\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "\n",
    "mnist_fnn_results = pd.concat([mnist_baseline_df, mnist_fnn_df, mnist_fnn_normal_df, mnist_fnn_uniform_df])\n",
    "\n",
    "plot_summary(mnist_fnn_results, \"MNIST FNN Test Accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_fnn_normal_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_FNN_NORMAL\"),\n",
    "                                               model_name=\"Unscaled bias\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "mnist_fnn_down_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_FNN_NORMAL_DOWN_SCALED\"),\n",
    "                                             model_name=\"Downscaled bias\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "mnist_fnn_up_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_FNN_NORMAL_UP_SCALED\"),\n",
    "                                           model_name=\"Upscaled bias\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "\n",
    "mnist_fnn_results = pd.concat([mnist_fnn_normal_df, mnist_fnn_down_df, mnist_fnn_up_df])\n",
    "\n",
    "plot_summary(mnist_fnn_results, \"MNIST FNN Scaled Test Accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 CNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "R_SEED = 4240\n",
    "MNIST_EPOCHS = 5\n",
    "\n",
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3.1 Models without zero initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.manual_seed(R_SEED)\n",
    "\n",
    "test_loader = get_dataloader(dataset=\"mnist\", train=False, batch_size=100)\n",
    "train_loader, validation_loader = get_dataloader(dataset=\"mnist\", train=True, batch_size=100, num_workers=1,\n",
    "                                                 worker_init_fn=seed_worker,\n",
    "                                                 generator=generator)\n",
    "\n",
    "model = MNISTCNNModel()\n",
    "\n",
    "trainer = Trainer(model, model_name=\"MNIST_CNN\")\n",
    "trainer.train(train_loader, validation_loader, MNIST_EPOCHS)\n",
    "trainer.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.manual_seed(R_SEED)\n",
    "\n",
    "test_loader = get_dataloader(dataset=\"mnist\", train=False, batch_size=16)\n",
    "train_loader, validation_loader = get_dataloader(dataset=\"mnist\", train=True, batch_size=16, num_workers=1,\n",
    "                                                 worker_init_fn=seed_worker,\n",
    "                                                 generator=generator)\n",
    "\n",
    "model = MNISTCNNModel()\n",
    "\n",
    "trainer = Trainer(model, model_name=\"MNIST_CNN_MINI_BATCH\")\n",
    "trainer.train(train_loader, validation_loader, MNIST_EPOCHS)\n",
    "trainer.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3.2 Experiments with zero initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "configs = [\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_ZERO\", epochs=MNIST_EPOCHS, batch_size=100, initialization_mode=\"zero\"),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_ZERO_SIGMOID\", epochs=MNIST_EPOCHS, batch_size=100, initialization_mode=\"zero\",\n",
    "                  activation_fun=Sigmoid()),\n",
    "\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_NORMAL\", epochs=MNIST_EPOCHS, batch_size=100, initialization_mode=\"normal\"),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_NORMAL_DOWN_SCALED\", epochs=MNIST_EPOCHS, batch_size=100,\n",
    "                  initialization_mode=\"normal\", initialization_factor=.01),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_NORMAL_UP_SCALED\", epochs=MNIST_EPOCHS, batch_size=100,\n",
    "                  initialization_mode=\"normal\", initialization_factor=100),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_NORMAL_SGD\", epochs=MNIST_EPOCHS, batch_size=100, initialization_mode=\"normal\",\n",
    "                  optimizer=SGD),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_NORMAL_MINI_BATCH\", epochs=MNIST_EPOCHS, batch_size=16,\n",
    "                  initialization_mode=\"normal\"),\n",
    "\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_UNIFORM\", epochs=MNIST_EPOCHS, batch_size=100, initialization_mode=\"uniform\"),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_UNIFORM_DOWN_SCALED\", epochs=MNIST_EPOCHS, batch_size=100,\n",
    "                  initialization_mode=\"uniform\", initialization_factor=.01),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_UNIFORM_UP_SCALED\", epochs=MNIST_EPOCHS, batch_size=100,\n",
    "                  initialization_mode=\"uniform\", initialization_factor=100),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_UNIFORM_SGD\", epochs=MNIST_EPOCHS, batch_size=100,\n",
    "                  initialization_mode=\"uniform\",\n",
    "                  optimizer=SGD),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_UNIFORM_MINI_BATCH\", epochs=MNIST_EPOCHS, batch_size=16,\n",
    "                  initialization_mode=\"uniform\"),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for config in configs:\n",
    "    model = MNISTCNNModel()\n",
    "    config.optimizer = config.optimizer if config.optimizer is None else config.optimizer(model.parameters(), lr=0.001)\n",
    "    run_experiment(model=model, dataset=\"mnist\", config=config, seed=R_SEED)\n",
    "    del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3.3 Final Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.initial_seed()\n",
    "random.seed()\n",
    "np.random.seed()\n",
    "\n",
    "MNIST_EPOCHS = 15\n",
    "BATCH_SIZE = 128\n",
    "RUNS = 5\n",
    "\n",
    "configs = [\n",
    "    TrainerConfig(model_name=\"MNIST_CNN\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE, initialization_mode=\"default\"),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_NORMAL\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                  initialization_mode=\"normal\"),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_UNIFORM\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                  initialization_mode=\"uniform\"),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_NORMAL_UP_SCALED\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                  initialization_mode=\"normal\", initialization_factor=100),\n",
    "    TrainerConfig(model_name=\"MNIST_CNN_NORMAL_DOWN_SCALED\", epochs=MNIST_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                  initialization_mode=\"normal\", initialization_factor=.01),\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    model = MNISTCNNModel()\n",
    "\n",
    "    run_experiment(model=model, dataset=\"mnist\", config=config, runs=5, train_summary=False, validation_summary=False,\n",
    "                   validate_after_epoch=False, test_after_epoch=True)\n",
    "    del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_baseline_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_FNN_BASELINE\"),\n",
    "                                             model_name=\"Baseline model\", n_runs=RUNS, n_epochs=10)\n",
    "mnist_cnn_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_CNN\"),\n",
    "                                        model_name=\"LeCun initialization\",\n",
    "                                        n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "mnist_cnn_normal_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_CNN_NORMAL\"),\n",
    "                                               model_name=\"Normal initialization\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "mnist_cnn_uniform_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_CNN_UNIFORM\"),\n",
    "                                                model_name=\"Uniform initialization\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "\n",
    "mnist_cnn_results = pd.concat([mnist_baseline_df, mnist_cnn_df, mnist_cnn_normal_df, mnist_cnn_uniform_df])\n",
    "\n",
    "plot_summary(mnist_cnn_results, \"MNIST CNN Test Accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_cnn_normal_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_CNN_NORMAL\"),\n",
    "                                               model_name=\"Unscaled bias\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "mnist_cnn_down_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_CNN_NORMAL_DOWN_SCALED\"),\n",
    "                                             model_name=\"Downscaled bias\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "mnist_cnn_up_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"MNIST_CNN_NORMAL_UP_SCALED\"),\n",
    "                                           model_name=\"Upscaled bias\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "\n",
    "mnist_cnn_results = pd.concat([mnist_cnn_normal_df, mnist_cnn_down_df, mnist_cnn_up_df])\n",
    "\n",
    "plot_summary(mnist_cnn_results, \"MNIST CNN Test Accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 CIFAR 10 dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "R_SEED = 4240\n",
    "CIFAR_EPOCHS = 10\n",
    "CIFAR_BATCH_SIZE = 100\n",
    "\n",
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.manual_seed(R_SEED)\n",
    "\n",
    "test_loader = get_dataloader(dataset=\"cifar10\", train=False, flatten=True, batch_size=CIFAR_BATCH_SIZE)\n",
    "train_loader, validation_loader = get_dataloader(dataset=\"cifar10\", train=True, flatten=True,\n",
    "                                                 batch_size=CIFAR_BATCH_SIZE, num_workers=1, worker_init_fn=seed_worker,\n",
    "                                                 generator=generator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Baseline Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LogisticRegression(32 * 32 * 3, 10)\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR_LOGISTIC\")\n",
    "trainer.train(train_loader, validation_loader, CIFAR_EPOCHS)\n",
    "trainer.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 FNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.1 Models without zero initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CIFARFNNModel()\n",
    "trainer = Trainer(model, model_name=\"CIFAR_FNN\")\n",
    "trainer.train(train_loader, validation_loader, CIFAR_EPOCHS)\n",
    "trainer.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.2 Experiments with zero initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CIFARFNNModel()\n",
    "model.zero_initialization(\"zero\")\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR10_FNN_ZERO\")\n",
    "trainer.train(train_loader, validation_loader, CIFAR_EPOCHS)\n",
    "trainer.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CIFARFNNModel()\n",
    "model.zero_initialization(\"uniform\")\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR10_FNN_UNIFORM\")\n",
    "trainer.train(train_loader, validation_loader, CIFAR_EPOCHS)\n",
    "trainer.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CIFARFNNModel()\n",
    "model.zero_initialization(\"normal\")\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR10_FNN_NORMAL\")\n",
    "trainer.train(train_loader, validation_loader, CIFAR_EPOCHS)\n",
    "trainer.test(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.3 Final Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.initial_seed()\n",
    "random.seed()\n",
    "np.random.seed()\n",
    "\n",
    "CIFAR_EPOCHS = 15\n",
    "CIFAR_BATCH_SIZE = 128\n",
    "RUNS = 5\n",
    "\n",
    "configs = [\n",
    "    TrainerConfig(model_name=\"CIFAR10_FNN_BASELINE\", epochs=CIFAR_EPOCHS, batch_size=CIFAR_BATCH_SIZE,\n",
    "                  initialization_mode=\"default\"),\n",
    "    TrainerConfig(model_name=\"CIFAR10_FNN\", epochs=CIFAR_EPOCHS, batch_size=CIFAR_BATCH_SIZE,\n",
    "                  initialization_mode=\"default\"),\n",
    "    TrainerConfig(model_name=\"CIFAR10_FNN_NORMAL\", epochs=CIFAR_EPOCHS, batch_size=CIFAR_BATCH_SIZE,\n",
    "                  initialization_mode=\"normal\"),\n",
    "    TrainerConfig(model_name=\"CIFAR10_FNN_UNIFORM\", epochs=CIFAR_EPOCHS, batch_size=CIFAR_BATCH_SIZE,\n",
    "                  initialization_mode=\"uniform\"),\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    if \"BASELINE\" in config.model_name:\n",
    "        model = LogisticRegression(32 * 32 * 3, 10)\n",
    "    else:\n",
    "        model = CIFARFNNModel()\n",
    "\n",
    "    run_experiment(model=model, dataset=\"cifar10\", config=config, runs=RUNS, train_summary=False,\n",
    "                   validation_summary=False, validate_after_epoch=False, test_after_epoch=True)\n",
    "    del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cifar_baseline_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_FNN_BASELINE\"),\n",
    "                                             model_name=\"Baseline model\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "cifar_fnn_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_FNN\"),\n",
    "                                        model_name=\"LeCun initialization\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "cifar_fnn_normal_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_FNN_NORMAL\"),\n",
    "                                               model_name=\"Normal initialization\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "cifar_fnn_uniform_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_FNN_UNIFORM\"),\n",
    "                                                model_name=\"Uniform initialization\", n_runs=RUNS, n_epochs=MNIST_EPOCHS)\n",
    "\n",
    "cifar_fnn_results = pd.concat([cifar_baseline_df, cifar_fnn_df, cifar_fnn_normal_df, cifar_fnn_uniform_df])\n",
    "\n",
    "plot_summary(cifar_fnn_results, \"CIFAR-10 FNN Test Accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "configs = [\n",
    "    TrainerConfig(model_name=\"CIFAR10_FNN_GRAD\", epochs=1, batch_size=128, initialization_mode=\"default\"),\n",
    "    TrainerConfig(model_name=\"CIFAR10_FNN_NORMAL_GRAD\", epochs=1, batch_size=128, initialization_mode=\"normal\"),\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    model = CIFARFNNModel(activation_fun=config.activation_fun)\n",
    "\n",
    "    run_experiment(model=model, dataset=\"cifar10\", config=config, runs=1, train_summary=True,\n",
    "                   validation_summary=False, validate_after_epoch=False, test_after_epoch=True)\n",
    "    del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fnn_df = read_gradient_summary_to_df(os.path.join(\"results\", \"CIFAR10_FNN_GRAD\"))\n",
    "fnn_normal_df = read_gradient_summary_to_df(os.path.join(\"results\", \"CIFAR10_FNN_NORMAL_GRAD\"))\n",
    "\n",
    "plot_gradient_distribution_comparison(fnn_df, \"CIFAR-10 FNN LeCun\", fnn_normal_df, \"CIFAR-10 FNN our approach\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 CNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "R_SEED = 4240\n",
    "\n",
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.1 Models without zero initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.manual_seed(R_SEED)\n",
    "\n",
    "test_loader = get_dataloader(dataset=\"cifar10\", train=False, batch_size=CIFAR_BATCH_SIZE)\n",
    "train_loader, validation_loader = get_dataloader(dataset=\"cifar10\", train=True, batch_size=CIFAR_BATCH_SIZE,\n",
    "                                                 num_workers=1,\n",
    "                                                 worker_init_fn=seed_worker, generator=generator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CIFARCNNModel()\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR10_CNN\")\n",
    "trainer.train(train_loader, validation_loader, CIFAR_EPOCHS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.2 Experiments with zero initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CIFARCNNModel()\n",
    "model.zero_initialization(\"zero\")\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR10_CNN_ZERO\")\n",
    "trainer.train(train_loader, validation_loader, CIFAR_EPOCHS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CIFARCNNModel()\n",
    "model.zero_initialization(\"uniform\")\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR10_CNN_UNIFORM\")\n",
    "trainer.train(train_loader, validation_loader, CIFAR_EPOCHS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CIFARCNNModel()\n",
    "model.zero_initialization(\"normal\")\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR10_CNN_NORMAL\")\n",
    "trainer.train(train_loader, validation_loader, CIFAR_EPOCHS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.3 Final Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.initial_seed()\n",
    "random.seed()\n",
    "np.random.seed()\n",
    "\n",
    "CIFAR_EPOCHS = 20\n",
    "CIFAR_BATCH_SIZE = 128\n",
    "RUNS = 5\n",
    "\n",
    "configs = [\n",
    "    TrainerConfig(model_name=\"CIFAR10_CNN\", epochs=CIFAR_EPOCHS, batch_size=CIFAR_BATCH_SIZE,\n",
    "                  initialization_mode=\"default\"),\n",
    "    TrainerConfig(model_name=\"CIFAR10_CNN_NORMAL\", epochs=CIFAR_EPOCHS, batch_size=CIFAR_BATCH_SIZE,\n",
    "                  initialization_mode=\"normal\"),\n",
    "    TrainerConfig(model_name=\"CIFAR10_CNN_UNIFORM\", epochs=CIFAR_EPOCHS, batch_size=CIFAR_BATCH_SIZE,\n",
    "                  initialization_mode=\"uniform\"),\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    model = CIFARCNNModel()\n",
    "\n",
    "run_experiment(model=model, dataset=\"cifar10\", config=config, runs=5, train_summary=False, validation_summary=False,\n",
    "               validate_after_epoch=False, test_after_epoch=True, test_final_model=False)\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cifar_baseline_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_FNN_BASELINE\"),\n",
    "                                             model_name=\"Baseline model\", n_runs=RUNS, n_epochs=15)\n",
    "cifar_cnn_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_CNN\"),\n",
    "                                        model_name=\"LeCun initialization\",\n",
    "                                        n_runs=RUNS, n_epochs=CIFAR_EPOCHS)\n",
    "cifar_cnn_normal_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_CNN_NORMAL\"),\n",
    "                                               model_name=\"Normal initialization\", n_runs=RUNS, n_epochs=CIFAR_EPOCHS)\n",
    "cifar_cnn_uniform_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_CNN_UNIFORM\"),\n",
    "                                                model_name=\"Uniform initialization\", n_runs=RUNS, n_epochs=CIFAR_EPOCHS)\n",
    "\n",
    "cifar_results = pd.concat([cifar_baseline_df, cifar_cnn_df, cifar_cnn_normal_df, cifar_cnn_uniform_df])\n",
    "\n",
    "plot_summary(cifar_results, \"CIFAR-10 CNN Test Accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.4 ResNet-50 model\n",
    "\n",
    "To confirm our conclusions on a more complex task we run the CIFAR-10 experiments for a ResNet-50 model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "R_SEED = 4240\n",
    "RESNET_EPOCHS = 20\n",
    "\n",
    "torch.manual_seed(R_SEED)\n",
    "random.seed(R_SEED)\n",
    "np.random.seed(R_SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "generator = Generator().manual_seed(R_SEED)\n",
    "\n",
    "test_loader = get_dataloader(dataset=\"cifar10\", train=False, batch_size=100, transform=transform_test)\n",
    "train_loader, validation_loader = get_dataloader(dataset=\"cifar10\", train=True, batch_size=128,\n",
    "                                                 transform=transform_train, num_workers=1, worker_init_fn=seed_worker,\n",
    "                                                 generator=generator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = ResNet50()\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR10_RESNET\")\n",
    "trainer.train(train_loader, validation_loader, num_epochs=RESNET_EPOCHS, train_summary=False, validate_after_epoch=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = ResNet50()\n",
    "model.zero_initialization(\"uniform\")\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR10_RESNET_UNIFORM\")\n",
    "trainer.train(train_loader, validation_loader, num_epochs=RESNET_EPOCHS, train_summary=False, validate_after_epoch=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = ResNet50()\n",
    "model.zero_initialization(\"normal\")\n",
    "\n",
    "trainer = Trainer(model, model_name=\"CIFAR10_RESNET_NORMAL\")\n",
    "trainer.train(train_loader, validation_loader, num_epochs=RESNET_EPOCHS, train_summary=False, validate_after_epoch=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4.1 Final Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.initial_seed()\n",
    "random.seed()\n",
    "np.random.seed()\n",
    "\n",
    "RESNET_EPOCHS = 30\n",
    "RESNET_BATCH_SIZE = 128\n",
    "RUNS = 5\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "configs = [\n",
    "    TrainerConfig(model_name=\"CIFAR10_RESNET\", epochs=RESNET_EPOCHS, batch_size=RESNET_BATCH_SIZE,\n",
    "                  initialization_mode=\"default\", transform_test=transform_test, transform_train=transform_train),\n",
    "    TrainerConfig(model_name=\"CIFAR10_RESNET_NORMAL\", epochs=RESNET_EPOCHS, batch_size=RESNET_BATCH_SIZE,\n",
    "                  initialization_mode=\"normal\", transform_test=transform_test, transform_train=transform_train),\n",
    "    TrainerConfig(model_name=\"CIFAR10_RESNET_UNIFORM\", epochs=RESNET_EPOCHS, batch_size=RESNET_BATCH_SIZE,\n",
    "                  initialization_mode=\"uniform\", transform_test=transform_test, transform_train=transform_train),\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    model = ResNet50()\n",
    "    run_experiment(model=model, dataset=\"cifar10\", config=config, runs=RUNS, train_summary=False,\n",
    "                   validation_summary=False,\n",
    "                   validate_after_epoch=False, test_after_epoch=True)\n",
    "    del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_RESNET\"), model_name=\"ResNet\",\n",
    "                                     n_runs=RUNS, n_epochs=RESNET_EPOCHS)\n",
    "resnet_normal_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_RESNET_NORMAL\"),\n",
    "                                            model_name=\"ResNet normal\", n_runs=RUNS, n_epochs=RESNET_EPOCHS)\n",
    "resnet_uniform_df = read_summary_files_to_df(summary_path=os.path.join(\"results\", \"CIFAR10_RESNET_UNIFORM\"),\n",
    "                                             model_name=\"ResNet uniform\", n_runs=RUNS, n_epochs=RESNET_EPOCHS)\n",
    "\n",
    "resnet_results = pd.concat([resnet_df, resnet_normal_df, resnet_uniform_df])\n",
    "\n",
    "plot_summary(resnet_results, \"ResNet-50 Test Accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
